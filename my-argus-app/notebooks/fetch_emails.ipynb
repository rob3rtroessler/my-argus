{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dc32aa2-0907-4a03-8e2a-1b19d68797c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gmail Email Fetcher\n",
    "\n",
    "This notebook fetches emails from Gmail API and stores them in `dev.core.emails` table.\n",
    "\n",
    "**Setup Requirements:**\n",
    "1. Create a Google Cloud Project with Gmail API enabled\n",
    "2. Create OAuth 2.0 credentials (Desktop app type)\n",
    "3. Store credentials in Databricks Secrets:\n",
    "   - `gmail/client_id`\n",
    "   - `gmail/client_secret`\n",
    "   - `gmail/refresh_token` (obtained after first OAuth flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34185679-5b1f-4592-bb39-45af8a225af9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install --quiet google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a29bada1-e8ff-4493-8f1d-6de042e8547c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import base64\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from typing import List, Dict, Any, Optional\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# For local testing, you can hardcode these. For production, use Databricks Secrets.\n",
    "\n",
    "# Option 1: Use Databricks Secrets (recommended for production)\n",
    "# CLIENT_ID = dbutils.secrets.get(scope=\"gmail\", key=\"client_id\")\n",
    "# CLIENT_SECRET = dbutils.secrets.get(scope=\"gmail\", key=\"client_secret\")\n",
    "# REFRESH_TOKEN = dbutils.secrets.get(scope=\"gmail\", key=\"refresh_token\")\n",
    "\n",
    "# Option 2: Hardcode for testing (NOT RECOMMENDED for production)\n",
    "CLIENT_ID = \"YOUR_CLIENT_ID_HERE\"\n",
    "CLIENT_SECRET = \"YOUR_CLIENT_SECRET_HERE\"\n",
    "REFRESH_TOKEN = \"YOUR_REFRESH_TOKEN_HERE\"\n",
    "\n",
    "# Configuration\n",
    "MAX_RESULTS = 100  # Number of emails to fetch per run\n",
    "TABLE_NAME = \"dev.core.emails\"\n",
    "\n",
    "print(f\"✓ Configuration loaded\")\n",
    "print(f\"  - Fetching up to {MAX_RESULTS} emails\")\n",
    "print(f\"  - Target table: {TABLE_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Gmail API\n",
    "def get_gmail_service():\n",
    "    \"\"\"Create and return Gmail API service using refresh token.\"\"\"\n",
    "    creds = Credentials(\n",
    "        token=None,\n",
    "        refresh_token=REFRESH_TOKEN,\n",
    "        token_uri=\"https://oauth2.googleapis.com/token\",\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        scopes=[\"https://www.googleapis.com/auth/gmail.readonly\"]\n",
    "    )\n",
    "    \n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "    return service\n",
    "\n",
    "try:\n",
    "    gmail_service = get_gmail_service()\n",
    "    print(\"✓ Gmail API authenticated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Authentication failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to parse email data\n",
    "def get_header(headers: List[Dict], name: str) -> Optional[str]:\n",
    "    \"\"\"Extract a specific header value from email headers.\"\"\"\n",
    "    for header in headers:\n",
    "        if header.get('name', '').lower() == name.lower():\n",
    "            return header.get('value')\n",
    "    return None\n",
    "\n",
    "def parse_email_addresses(header_value: Optional[str]) -> List[str]:\n",
    "    \"\"\"Parse email addresses from a header value.\"\"\"\n",
    "    if not header_value:\n",
    "        return None\n",
    "    # Simple parsing - split by comma and extract email addresses\n",
    "    import re\n",
    "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', header_value)\n",
    "    return emails if emails else None\n",
    "\n",
    "def decode_body(part: Dict) -> Optional[str]:\n",
    "    \"\"\"Decode email body from base64.\"\"\"\n",
    "    if 'data' in part.get('body', {}):\n",
    "        try:\n",
    "            return base64.urlsafe_b64decode(part['body']['data']).decode('utf-8', errors='ignore')\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def extract_body_parts(payload: Dict) -> tuple:\n",
    "    \"\"\"Extract text and HTML body from email payload.\"\"\"\n",
    "    text_body = None\n",
    "    html_body = None\n",
    "    \n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            mime_type = part.get('mimeType', '')\n",
    "            if mime_type == 'text/plain' and not text_body:\n",
    "                text_body = decode_body(part)\n",
    "            elif mime_type == 'text/html' and not html_body:\n",
    "                html_body = decode_body(part)\n",
    "            elif mime_type.startswith('multipart/'):\n",
    "                # Recursively check nested parts\n",
    "                if 'parts' in part:\n",
    "                    for subpart in part['parts']:\n",
    "                        sub_mime = subpart.get('mimeType', '')\n",
    "                        if sub_mime == 'text/plain' and not text_body:\n",
    "                            text_body = decode_body(subpart)\n",
    "                        elif sub_mime == 'text/html' and not html_body:\n",
    "                            html_body = decode_body(subpart)\n",
    "    else:\n",
    "        # Single part message\n",
    "        mime_type = payload.get('mimeType', '')\n",
    "        if mime_type == 'text/plain':\n",
    "            text_body = decode_body(payload)\n",
    "        elif mime_type == 'text/html':\n",
    "            html_body = decode_body(payload)\n",
    "    \n",
    "    return text_body, html_body\n",
    "\n",
    "def extract_attachments(payload: Dict) -> List[Dict]:\n",
    "    \"\"\"Extract attachment metadata from email payload.\"\"\"\n",
    "    attachments = []\n",
    "    \n",
    "    def process_part(part):\n",
    "        filename = part.get('filename')\n",
    "        if filename:\n",
    "            attachments.append({\n",
    "                'filename': filename,\n",
    "                'mime_type': part.get('mimeType'),\n",
    "                'size_bytes': part.get('body', {}).get('size', 0),\n",
    "                'attachment_id': part.get('body', {}).get('attachmentId')\n",
    "            })\n",
    "        \n",
    "        # Check nested parts\n",
    "        if 'parts' in part:\n",
    "            for subpart in part['parts']:\n",
    "                process_part(subpart)\n",
    "    \n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            process_part(part)\n",
    "    \n",
    "    return attachments if attachments else None\n",
    "\n",
    "print(\"✓ Helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch emails from Gmail\n",
    "def fetch_recent_emails(service, max_results=100):\n",
    "    \"\"\"Fetch recent emails from Gmail.\"\"\"\n",
    "    try:\n",
    "        # Get list of message IDs\n",
    "        results = service.users().messages().list(\n",
    "            userId='me',\n",
    "            maxResults=max_results,\n",
    "            labelIds=['INBOX']  # You can modify this to fetch from different labels\n",
    "        ).execute()\n",
    "        \n",
    "        messages = results.get('messages', [])\n",
    "        print(f\"✓ Found {len(messages)} messages to process\")\n",
    "        \n",
    "        email_data = []\n",
    "        \n",
    "        for i, msg in enumerate(messages):\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Processing message {i + 1}/{len(messages)}...\")\n",
    "            \n",
    "            # Get full message details\n",
    "            message = service.users().messages().get(\n",
    "                userId='me',\n",
    "                id=msg['id'],\n",
    "                format='full'\n",
    "            ).execute()\n",
    "            \n",
    "            # Parse message\n",
    "            headers = message['payload'].get('headers', [])\n",
    "            \n",
    "            # Extract header fields\n",
    "            subject = get_header(headers, 'Subject')\n",
    "            from_header = get_header(headers, 'From')\n",
    "            to_header = get_header(headers, 'To')\n",
    "            cc_header = get_header(headers, 'Cc')\n",
    "            bcc_header = get_header(headers, 'Bcc')\n",
    "            reply_to = get_header(headers, 'Reply-To')\n",
    "            in_reply_to = get_header(headers, 'In-Reply-To')\n",
    "            references_header = get_header(headers, 'References')\n",
    "            date_header = get_header(headers, 'Date')\n",
    "            \n",
    "            # Parse from field for name and email\n",
    "            from_name = None\n",
    "            from_email = None\n",
    "            if from_header:\n",
    "                import re\n",
    "                match = re.match(r'^(.*?)\\s*<(.+?)>$', from_header)\n",
    "                if match:\n",
    "                    from_name = match.group(1).strip('\"')\n",
    "                    from_email = match.group(2)\n",
    "                else:\n",
    "                    from_email = from_header\n",
    "            \n",
    "            # Parse recipients\n",
    "            to_recipients = parse_email_addresses(to_header)\n",
    "            cc_recipients = parse_email_addresses(cc_header)\n",
    "            bcc_recipients = parse_email_addresses(bcc_header)\n",
    "            \n",
    "            # Parse references\n",
    "            references = references_header.split() if references_header else None\n",
    "            \n",
    "            # Extract body\n",
    "            text_body, html_body = extract_body_parts(message['payload'])\n",
    "            \n",
    "            # Extract attachments\n",
    "            attachments = extract_attachments(message['payload'])\n",
    "            \n",
    "            # Parse timestamps\n",
    "            internal_date = datetime.fromtimestamp(\n",
    "                int(message['internalDate']) / 1000, \n",
    "                tz=timezone.utc\n",
    "            )\n",
    "            \n",
    "            # Parse date header (sent_at)\n",
    "            sent_at = None\n",
    "            if date_header:\n",
    "                try:\n",
    "                    from email.utils import parsedate_to_datetime\n",
    "                    sent_at = parsedate_to_datetime(date_header)\n",
    "                except:\n",
    "                    sent_at = internal_date\n",
    "            \n",
    "            # Determine read status\n",
    "            is_read = 'UNREAD' not in message.get('labelIds', [])\n",
    "            is_starred = 'STARRED' in message.get('labelIds', [])\n",
    "            spam_flag = 'SPAM' in message.get('labelIds', [])\n",
    "            \n",
    "            email_data.append({\n",
    "                'email_id': message['id'],\n",
    "                'thread_id': message['threadId'],\n",
    "                'subject': subject,\n",
    "                'from_name': from_name,\n",
    "                'from_email': from_email,\n",
    "                'reply_to': reply_to,\n",
    "                'in_reply_to': in_reply_to,\n",
    "                'references': references,\n",
    "                'to_recipients': to_recipients,\n",
    "                'cc_recipients': cc_recipients,\n",
    "                'bcc_recipients': bcc_recipients,\n",
    "                'sent_at': sent_at,\n",
    "                'received_at': internal_date,\n",
    "                'gmail_internal_date': internal_date,\n",
    "                'received_date': internal_date.date(),\n",
    "                'snippet': message.get('snippet'),\n",
    "                'body_text': text_body,\n",
    "                'body_html': html_body,\n",
    "                'raw_headers': None,  # Can store json.dumps(headers) if needed\n",
    "                'labels': message.get('labelIds'),\n",
    "                'is_read': is_read,\n",
    "                'is_starred': is_starred,\n",
    "                'importance': None,  # Can parse from headers if needed\n",
    "                'spam_flag': spam_flag,\n",
    "                'message_size_bytes': message.get('sizeEstimate'),\n",
    "                'has_attachments': attachments is not None,\n",
    "                'attachments': attachments,\n",
    "                'gmail_history_id': message.get('historyId'),\n",
    "                'created_at': datetime.now(timezone.utc),\n",
    "                'updated_at': None\n",
    "            })\n",
    "        \n",
    "        print(f\"✓ Processed {len(email_data)} emails\")\n",
    "        return email_data\n",
    "        \n",
    "    except HttpError as error:\n",
    "        print(f'✗ An error occurred: {error}')\n",
    "        raise\n",
    "\n",
    "# Fetch emails\n",
    "emails = fetch_recent_emails(gmail_service, MAX_RESULTS)\n",
    "print(f\"\\n✓ Fetched {len(emails)} emails from Gmail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Spark DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, LongType, TimestampType, DateType, ArrayType\n",
    "\n",
    "# Define schema matching the table\n",
    "email_schema = StructType([\n",
    "    StructField(\"email_id\", StringType(), False),\n",
    "    StructField(\"thread_id\", StringType(), True),\n",
    "    StructField(\"subject\", StringType(), True),\n",
    "    StructField(\"from_name\", StringType(), True),\n",
    "    StructField(\"from_email\", StringType(), True),\n",
    "    StructField(\"reply_to\", StringType(), True),\n",
    "    StructField(\"in_reply_to\", StringType(), True),\n",
    "    StructField(\"references\", ArrayType(StringType()), True),\n",
    "    StructField(\"to_recipients\", ArrayType(StringType()), True),\n",
    "    StructField(\"cc_recipients\", ArrayType(StringType()), True),\n",
    "    StructField(\"bcc_recipients\", ArrayType(StringType()), True),\n",
    "    StructField(\"sent_at\", TimestampType(), True),\n",
    "    StructField(\"received_at\", TimestampType(), True),\n",
    "    StructField(\"gmail_internal_date\", TimestampType(), True),\n",
    "    StructField(\"received_date\", DateType(), True),\n",
    "    StructField(\"snippet\", StringType(), True),\n",
    "    StructField(\"body_text\", StringType(), True),\n",
    "    StructField(\"body_html\", StringType(), True),\n",
    "    StructField(\"raw_headers\", StringType(), True),\n",
    "    StructField(\"labels\", ArrayType(StringType()), True),\n",
    "    StructField(\"is_read\", BooleanType(), True),\n",
    "    StructField(\"is_starred\", BooleanType(), True),\n",
    "    StructField(\"importance\", StringType(), True),\n",
    "    StructField(\"spam_flag\", BooleanType(), True),\n",
    "    StructField(\"message_size_bytes\", LongType(), True),\n",
    "    StructField(\"has_attachments\", BooleanType(), True),\n",
    "    StructField(\"attachments\", ArrayType(StructType([\n",
    "        StructField(\"filename\", StringType(), True),\n",
    "        StructField(\"mime_type\", StringType(), True),\n",
    "        StructField(\"size_bytes\", LongType(), True),\n",
    "        StructField(\"attachment_id\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"gmail_history_id\", StringType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True),\n",
    "    StructField(\"updated_at\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(emails, schema=email_schema)\n",
    "\n",
    "print(f\"✓ Created Spark DataFrame with {df.count()} rows\")\n",
    "df.printSchema()\n",
    "display(df.select(\"email_id\", \"subject\", \"from_email\", \"received_at\", \"is_read\").limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert into Delta table (merge on email_id to avoid duplicates)\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Check if table exists\n",
    "table_exists = spark.catalog.tableExists(TABLE_NAME)\n",
    "\n",
    "if table_exists:\n",
    "    print(f\"✓ Table {TABLE_NAME} exists, performing MERGE (upsert)...\")\n",
    "    \n",
    "    # Get existing table\n",
    "    delta_table = DeltaTable.forName(spark, TABLE_NAME)\n",
    "    \n",
    "    # Perform merge (upsert based on email_id)\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        df.alias(\"source\"),\n",
    "        \"target.email_id = source.email_id\"\n",
    "    ).whenMatchedUpdateAll(\n",
    "    ).whenNotMatchedInsertAll(\n",
    "    ).execute()\n",
    "    \n",
    "    print(f\"✓ MERGE completed successfully\")\n",
    "    \n",
    "else:\n",
    "    print(f\"✓ Table {TABLE_NAME} does not exist, creating and inserting data...\")\n",
    "    \n",
    "    # Write as new table\n",
    "    df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"received_date\") \\\n",
    "        .option(\"delta.columnMapping.mode\", \"name\") \\\n",
    "        .option(\"delta.minReaderVersion\", \"2\") \\\n",
    "        .option(\"delta.minWriterVersion\", \"5\") \\\n",
    "        .saveAsTable(TABLE_NAME)\n",
    "    \n",
    "    print(f\"✓ Table created and data inserted successfully\")\n",
    "\n",
    "# Show summary\n",
    "result_count = spark.table(TABLE_NAME).count()\n",
    "print(f\"\\n✓ Total emails in table: {result_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data\n",
    "print(\"Sample of latest emails:\")\n",
    "display(\n",
    "    spark.table(TABLE_NAME)\n",
    "    .orderBy(col(\"received_at\").desc())\n",
    "    .select(\"email_id\", \"subject\", \"from_name\", \"from_email\", \"received_at\", \"is_read\", \"is_starred\")\n",
    "    .limit(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af933fb9-d5fc-48fe-b0f0-cd4341e64cef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8286925551890533,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-11-16 13_42_18",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
